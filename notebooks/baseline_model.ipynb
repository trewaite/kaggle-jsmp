{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "#modeling\n",
    "from sklearn.feature_selection import chi2, f_regression, VarianceThreshold\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "\n",
    "#metrics\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "SEED = 26\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility_score(df_eval, action_col='pred'):\n",
    "    i_size = df_eval['date'].nunique()\n",
    "    df_eval['score'] = df_eval['weight']*df_eval['resp']*df_eval[action_col]\n",
    "    pi = df_eval.groupby('date').sum()['score'].values\n",
    "    pi_squared = np.power(pi,2)\n",
    "    t = (np.sum(pi)/np.sqrt(np.sum(pi_squared)))*np.sqrt(250/i_size)\n",
    "    u = min(max(t,0),6)*np.sum(pi)\n",
    "    return u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Feature Engineered Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 8s, sys: 22.7 s, total: 1min 31s\n",
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dtype_dict = {}\n",
    "for f in range(0,130):\n",
    "    dtype_dict[f'feature_{f}'] = 'float32'\n",
    "df = pd.read_csv('../inputs/train.csv')\n",
    "#df = pd.read_csv('../preprocessed/simple_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2390491 entries, 0 to 2390490\n",
      "Columns: 138 entries, date to ts_id\n",
      "dtypes: float64(135), int64(3)\n",
      "memory usage: 2.5 GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['feature_0'] = df['feature_0'].replace(-1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 553 ms, sys: 10.1 ms, total: 563 ms\n",
      "Wall time: 1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_fold_ind = pd.read_csv('../preprocessed/train_fold_ind.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_fold_ind['fold'].value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,train_fold_ind[['fold']]],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple binary target, if resp > 0 \n",
    "df['target'] = df['resp'].apply(lambda x: 1 if x > 0 else 0)\n",
    "#df['target'] = df['resp'] # for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['target'].value_counts().plot(kind='bar')\n",
    "plt.title(\"Class Balance\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop and Index Non-Feature Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['resp_1','resp_2','resp_3','resp_4'], axis=1)\n",
    "df = df.set_index(['date','ts_id','weight','resp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill with 0 as all features scaled...therefore mean is 0\n",
    "df = df.fillna(value=0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = [col for col in df.columns if col not in ['fold','target']]\n",
    "drop_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_122</th>\n",
       "      <th>feature_123</th>\n",
       "      <th>feature_124</th>\n",
       "      <th>feature_125</th>\n",
       "      <th>feature_126</th>\n",
       "      <th>feature_127</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "      <th>fold</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>ts_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>resp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <th>0.000</th>\n",
       "      <th>0.006</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.873</td>\n",
       "      <td>-2.191</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>-0.323</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>...</td>\n",
       "      <td>1.168</td>\n",
       "      <td>8.314</td>\n",
       "      <td>1.782</td>\n",
       "      <td>14.018</td>\n",
       "      <td>2.653</td>\n",
       "      <td>12.600</td>\n",
       "      <td>2.301</td>\n",
       "      <td>11.446</td>\n",
       "      <td>train_fold</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>16.674</th>\n",
       "      <th>-0.010</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.350</td>\n",
       "      <td>-1.705</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.179</td>\n",
       "      <td>1.777</td>\n",
       "      <td>-0.915</td>\n",
       "      <td>2.832</td>\n",
       "      <td>-1.417</td>\n",
       "      <td>2.297</td>\n",
       "      <td>-1.305</td>\n",
       "      <td>1.899</td>\n",
       "      <td>train_fold</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0.000</th>\n",
       "      <th>0.024</th>\n",
       "      <td>0</td>\n",
       "      <td>0.813</td>\n",
       "      <td>-0.256</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.400</td>\n",
       "      <td>-0.614</td>\n",
       "      <td>-0.355</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.448</td>\n",
       "      <td>...</td>\n",
       "      <td>6.116</td>\n",
       "      <td>9.668</td>\n",
       "      <td>5.543</td>\n",
       "      <td>11.672</td>\n",
       "      <td>7.282</td>\n",
       "      <td>10.060</td>\n",
       "      <td>6.638</td>\n",
       "      <td>9.427</td>\n",
       "      <td>train_fold</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>0.000</th>\n",
       "      <th>-0.003</th>\n",
       "      <td>0</td>\n",
       "      <td>1.174</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-1.006</td>\n",
       "      <td>-0.676</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.508</td>\n",
       "      <td>...</td>\n",
       "      <td>2.839</td>\n",
       "      <td>0.499</td>\n",
       "      <td>3.034</td>\n",
       "      <td>1.513</td>\n",
       "      <td>4.398</td>\n",
       "      <td>1.266</td>\n",
       "      <td>3.856</td>\n",
       "      <td>1.013</td>\n",
       "      <td>train_fold</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>0.139</th>\n",
       "      <th>-0.003</th>\n",
       "      <td>1</td>\n",
       "      <td>-3.172</td>\n",
       "      <td>-3.093</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345</td>\n",
       "      <td>4.101</td>\n",
       "      <td>0.614</td>\n",
       "      <td>6.623</td>\n",
       "      <td>0.800</td>\n",
       "      <td>5.233</td>\n",
       "      <td>0.363</td>\n",
       "      <td>3.927</td>\n",
       "      <td>train_fold</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          feature_0  feature_1  feature_2  feature_3  \\\n",
       "date ts_id weight resp                                                 \n",
       "0    0     0.000  0.006           1     -1.873     -2.191     -0.474   \n",
       "     1     16.674 -0.010          0     -1.350     -1.705      0.068   \n",
       "     2     0.000  0.024           0      0.813     -0.256      0.806   \n",
       "     3     0.000  -0.003          0      1.174      0.345      0.067   \n",
       "     4     0.139  -0.003          1     -3.172     -3.093     -0.162   \n",
       "\n",
       "                          feature_4  feature_5  feature_6  feature_7  \\\n",
       "date ts_id weight resp                                                 \n",
       "0    0     0.000  0.006      -0.323      0.015     -0.002      0.000   \n",
       "     1     16.674 -0.010      0.028      0.194      0.138      0.000   \n",
       "     2     0.000  0.024       0.400     -0.614     -0.355      0.000   \n",
       "     3     0.000  -0.003      0.009     -1.006     -0.676      0.000   \n",
       "     4     0.139  -0.003     -0.128     -0.195     -0.144      0.000   \n",
       "\n",
       "                          feature_8  feature_9  ...  feature_122  feature_123  \\\n",
       "date ts_id weight resp                          ...                             \n",
       "0    0     0.000  0.006       0.000     -0.990  ...        1.168        8.314   \n",
       "     1     16.674 -0.010      0.000     -0.152  ...       -1.179        1.777   \n",
       "     2     0.000  0.024       0.000      5.448  ...        6.116        9.668   \n",
       "     3     0.000  -0.003      0.000      4.508  ...        2.839        0.499   \n",
       "     4     0.139  -0.003      0.000      2.683  ...        0.345        4.101   \n",
       "\n",
       "                          feature_124  feature_125  feature_126  feature_127  \\\n",
       "date ts_id weight resp                                                         \n",
       "0    0     0.000  0.006         1.782       14.018        2.653       12.600   \n",
       "     1     16.674 -0.010       -0.915        2.832       -1.417        2.297   \n",
       "     2     0.000  0.024         5.543       11.672        7.282       10.060   \n",
       "     3     0.000  -0.003        3.034        1.513        4.398        1.266   \n",
       "     4     0.139  -0.003        0.614        6.623        0.800        5.233   \n",
       "\n",
       "                          feature_128  feature_129        fold  target  \n",
       "date ts_id weight resp                                                  \n",
       "0    0     0.000  0.006         2.301       11.446  train_fold       1  \n",
       "     1     16.674 -0.010       -1.305        1.899  train_fold       0  \n",
       "     2     0.000  0.024         6.638        9.427  train_fold       1  \n",
       "     3     0.000  -0.003        3.856        1.013  train_fold       0  \n",
       "     4     0.139  -0.003        0.363        3.927  train_fold       0  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.4 s, sys: 5.82 s, total: 8.22 s\n",
      "Wall time: 8.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f_reg_results = f_regression(X=df[df['fold']=='train_fold'][all_features].values,\n",
    "                             y=df[df['fold']=='train_fold']['target'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_reg_results = pd.DataFrame(list(zip(all_features,f_reg_results[1])),columns=['feature','p_value']).sort_values(by='p_value',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>feature_111</td>\n",
       "      <td>0.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>feature_96</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>feature_127</td>\n",
       "      <td>0.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>feature_121</td>\n",
       "      <td>0.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>feature_108</td>\n",
       "      <td>0.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feature_4</td>\n",
       "      <td>0.306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>feature_98</td>\n",
       "      <td>0.377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>feature_5</td>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>feature_93</td>\n",
       "      <td>0.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>feature_78</td>\n",
       "      <td>0.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>feature_83</td>\n",
       "      <td>0.632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>feature_84</td>\n",
       "      <td>0.682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>feature_110</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>feature_115</td>\n",
       "      <td>0.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>feature_86</td>\n",
       "      <td>0.852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>feature_125</td>\n",
       "      <td>0.862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feature_3</td>\n",
       "      <td>0.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>feature_74</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature  p_value\n",
       "111  feature_111    0.101\n",
       "96    feature_96    0.107\n",
       "127  feature_127    0.148\n",
       "121  feature_121    0.177\n",
       "108  feature_108    0.211\n",
       "4      feature_4    0.306\n",
       "98    feature_98    0.377\n",
       "5      feature_5    0.471\n",
       "93    feature_93    0.485\n",
       "78    feature_78    0.579\n",
       "83    feature_83    0.632\n",
       "84    feature_84    0.682\n",
       "110  feature_110    0.800\n",
       "115  feature_115    0.801\n",
       "86    feature_86    0.852\n",
       "125  feature_125    0.862\n",
       "3      feature_3    0.899\n",
       "74    feature_74    0.968"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_reg_results[f_reg_results['p_value']>0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_122</th>\n",
       "      <th>feature_123</th>\n",
       "      <th>feature_124</th>\n",
       "      <th>feature_125</th>\n",
       "      <th>feature_126</th>\n",
       "      <th>feature_127</th>\n",
       "      <th>feature_128</th>\n",
       "      <th>feature_129</th>\n",
       "      <th>fold</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>ts_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>resp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <th>0.000</th>\n",
       "      <th>0.006</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.873</td>\n",
       "      <td>-2.191</td>\n",
       "      <td>-0.474</td>\n",
       "      <td>-0.323</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>...</td>\n",
       "      <td>1.168</td>\n",
       "      <td>8.314</td>\n",
       "      <td>1.782</td>\n",
       "      <td>14.018</td>\n",
       "      <td>2.653</td>\n",
       "      <td>12.600</td>\n",
       "      <td>2.301</td>\n",
       "      <td>11.446</td>\n",
       "      <td>train_fold</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>16.674</th>\n",
       "      <th>-0.010</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.350</td>\n",
       "      <td>-1.705</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.179</td>\n",
       "      <td>1.777</td>\n",
       "      <td>-0.915</td>\n",
       "      <td>2.832</td>\n",
       "      <td>-1.417</td>\n",
       "      <td>2.297</td>\n",
       "      <td>-1.305</td>\n",
       "      <td>1.899</td>\n",
       "      <td>train_fold</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0.000</th>\n",
       "      <th>0.024</th>\n",
       "      <td>0</td>\n",
       "      <td>0.813</td>\n",
       "      <td>-0.256</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.400</td>\n",
       "      <td>-0.614</td>\n",
       "      <td>-0.355</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.448</td>\n",
       "      <td>...</td>\n",
       "      <td>6.116</td>\n",
       "      <td>9.668</td>\n",
       "      <td>5.543</td>\n",
       "      <td>11.672</td>\n",
       "      <td>7.282</td>\n",
       "      <td>10.060</td>\n",
       "      <td>6.638</td>\n",
       "      <td>9.427</td>\n",
       "      <td>train_fold</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>0.000</th>\n",
       "      <th>-0.003</th>\n",
       "      <td>0</td>\n",
       "      <td>1.174</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-1.006</td>\n",
       "      <td>-0.676</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.508</td>\n",
       "      <td>...</td>\n",
       "      <td>2.839</td>\n",
       "      <td>0.499</td>\n",
       "      <td>3.034</td>\n",
       "      <td>1.513</td>\n",
       "      <td>4.398</td>\n",
       "      <td>1.266</td>\n",
       "      <td>3.856</td>\n",
       "      <td>1.013</td>\n",
       "      <td>train_fold</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>0.139</th>\n",
       "      <th>-0.003</th>\n",
       "      <td>1</td>\n",
       "      <td>-3.172</td>\n",
       "      <td>-3.093</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345</td>\n",
       "      <td>4.101</td>\n",
       "      <td>0.614</td>\n",
       "      <td>6.623</td>\n",
       "      <td>0.800</td>\n",
       "      <td>5.233</td>\n",
       "      <td>0.363</td>\n",
       "      <td>3.927</td>\n",
       "      <td>train_fold</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          feature_0  feature_1  feature_2  feature_3  \\\n",
       "date ts_id weight resp                                                 \n",
       "0    0     0.000  0.006           1     -1.873     -2.191     -0.474   \n",
       "     1     16.674 -0.010          0     -1.350     -1.705      0.068   \n",
       "     2     0.000  0.024           0      0.813     -0.256      0.806   \n",
       "     3     0.000  -0.003          0      1.174      0.345      0.067   \n",
       "     4     0.139  -0.003          1     -3.172     -3.093     -0.162   \n",
       "\n",
       "                          feature_4  feature_5  feature_6  feature_7  \\\n",
       "date ts_id weight resp                                                 \n",
       "0    0     0.000  0.006      -0.323      0.015     -0.002      0.000   \n",
       "     1     16.674 -0.010      0.028      0.194      0.138      0.000   \n",
       "     2     0.000  0.024       0.400     -0.614     -0.355      0.000   \n",
       "     3     0.000  -0.003      0.009     -1.006     -0.676      0.000   \n",
       "     4     0.139  -0.003     -0.128     -0.195     -0.144      0.000   \n",
       "\n",
       "                          feature_8  feature_9  ...  feature_122  feature_123  \\\n",
       "date ts_id weight resp                          ...                             \n",
       "0    0     0.000  0.006       0.000     -0.990  ...        1.168        8.314   \n",
       "     1     16.674 -0.010      0.000     -0.152  ...       -1.179        1.777   \n",
       "     2     0.000  0.024       0.000      5.448  ...        6.116        9.668   \n",
       "     3     0.000  -0.003      0.000      4.508  ...        2.839        0.499   \n",
       "     4     0.139  -0.003      0.000      2.683  ...        0.345        4.101   \n",
       "\n",
       "                          feature_124  feature_125  feature_126  feature_127  \\\n",
       "date ts_id weight resp                                                         \n",
       "0    0     0.000  0.006         1.782       14.018        2.653       12.600   \n",
       "     1     16.674 -0.010       -0.915        2.832       -1.417        2.297   \n",
       "     2     0.000  0.024         5.543       11.672        7.282       10.060   \n",
       "     3     0.000  -0.003        3.034        1.513        4.398        1.266   \n",
       "     4     0.139  -0.003        0.614        6.623        0.800        5.233   \n",
       "\n",
       "                          feature_128  feature_129        fold  target  \n",
       "date ts_id weight resp                                                  \n",
       "0    0     0.000  0.006         2.301       11.446  train_fold       1  \n",
       "     1     16.674 -0.010       -1.305        1.899  train_fold       0  \n",
       "     2     0.000  0.024         6.638        9.427  train_fold       1  \n",
       "     3     0.000  -0.003        3.856        1.013  train_fold       0  \n",
       "     4     0.139  -0.003        0.363        3.927  train_fold       0  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(estimator):\n",
    "    \n",
    "    results = {}\n",
    "    df_test_results = pd.DataFrame()\n",
    "    \n",
    "    results['estimator'] = {}\n",
    "    results['train_auc'] = {}\n",
    "    results['train_acc'] = {}\n",
    "    results['test_auc'] = {}\n",
    "    results['test_acc'] = {}\n",
    "    results['utility_score'] = {}\n",
    "        \n",
    "    lr_model = deepcopy(estimator)\n",
    "    \n",
    "    train_fold_list = ['train_fold']\n",
    "\n",
    "    for fold in tqdm(range(0, df['fold'].nunique()-1, 1)):\n",
    "\n",
    "        # split fold\n",
    "        train_fold_list.append(f'fold_{fold}')\n",
    "        df_train = df[df['fold'].isin(train_fold_list[0:-1])]\n",
    "        df_test = df[df['fold'].isin([train_fold_list[-1]])]\n",
    "        \n",
    "        df_train = df_train.drop('fold', axis=1)\n",
    "        df_test = df_test.drop('fold', axis=1)\n",
    "\n",
    "        # make X,y\n",
    "        X_train = df_train.drop('target', axis=1)\n",
    "        y_train = df_train['target'].values\n",
    "        X_test = df_test.drop('target', axis=1)\n",
    "        y_test = df_test['target'].values\n",
    "\n",
    "        print(f\"Fitting Fold {train_fold_list[0:-1]} Model ({X_train.shape[0]} samples) ...\")\n",
    "        lr_model.fit(X_train,y_train)\n",
    "\n",
    "        # make predictions\n",
    "        train_pred_prob = lr_model.predict_proba(X_train)[:,1]\n",
    "        train_pred = np.where(train_pred_prob>0.5,1,0)\n",
    "\n",
    "        test_pred_prob = lr_model.predict_proba(X_test)[:,1]\n",
    "        test_pred = np.where(test_pred_prob>0.5,1,0)\n",
    "        \n",
    "        print(\"Example Probs: \", test_pred_prob[0:5])\n",
    "\n",
    "        print(\"Complete.\\n\")\n",
    "\n",
    "        # calculate scores\n",
    "        train_auc = roc_auc_score(y_train, train_pred_prob)\n",
    "        train_acc = accuracy_score(y_train, train_pred)\n",
    "\n",
    "        test_auc = roc_auc_score(y_test, test_pred_prob)\n",
    "        test_acc = accuracy_score(y_test, test_pred)\n",
    "\n",
    "        print(f\"Fold {train_fold_list[0:-1]} Train Scores: \")\n",
    "        print(f\"AUC: {train_auc}\")\n",
    "        print(f\"Accuracy: {train_acc}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "        print(f\"Fold {train_fold_list[-1]} Test Scores: \")\n",
    "        print(f\"AUC: {test_auc}\")\n",
    "        print(f\"Accuracy: {test_acc}\")\n",
    "        \n",
    "        \n",
    "        # save fold results\n",
    "        results_df = df_test.reset_index()[['date','weight','resp']].copy()\n",
    "        results_df['fold'] = train_fold_list[-1]\n",
    "        results_df['actual'] = y_test\n",
    "        results_df['pred_prob'] = test_pred_prob\n",
    "        results_df['pred'] = test_pred\n",
    "        df_test_results = df_test_results.append(results_df)\n",
    "        \n",
    "        u = utility_score(results_df, action_col='pred')\n",
    "        print(\"Utility Score: \", u)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        results['estimator'][train_fold_list[-1]] = lr_model\n",
    "        results['train_auc'][train_fold_list[-1]] = train_auc\n",
    "        results['train_acc'][train_fold_list[-1]] = train_acc\n",
    "        results['test_auc'][train_fold_list[-1]] = test_auc\n",
    "        results['test_acc'][train_fold_list[-1]] = test_acc    \n",
    "        results['utility_score'][train_fold_list[-1]] = u\n",
    "        \n",
    "    return results, df_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-913c57cb0616>:17: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for fold in tqdm(range(0, df['fold'].nunique()-1, 1)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa9b4864ce04658a9f1ab8be41c1e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Fold ['train_fold'] Model (1403069 samples) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/f/code/kaggle-jsmp/env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Probs:  [0.49956299 0.4857311  0.49701603 0.51390444 0.50687493]\n",
      "Complete.\n",
      "\n",
      "Fold ['train_fold'] Train Scores: \n",
      "AUC: 0.5364557783496895\n",
      "Accuracy: 0.5249421090480939\n",
      "\n",
      "\n",
      "Fold fold_0 Test Scores: \n",
      "AUC: 0.5197246361917841\n",
      "Accuracy: 0.5135065386794728\n",
      "Utility Score:  650.2750255009807\n",
      "\n",
      "\n",
      "Fitting Fold ['train_fold', 'fold_0'] Model (1581316 samples) ...\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimator = LogisticRegression(solver='sag',penalty='l2')\n",
    "lr_results_dict, lr_results_df = run_models(estimator=estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lr_results_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-5ee449ae271c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlr_results_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lr_results_dict' is not defined"
     ]
    }
   ],
   "source": [
    "lr_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_results_df = lr_results_df.sort_values('pred_prob',ascending=False)\n",
    "lr_results_df['correct'] = lr_results_df.apply(lambda x: 1 if x['actual']==x['pred'] else 0, axis=1)\n",
    "lr_results_df['precision'] = lr_results_df['correct'].expanding().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_results_df['pred_prob'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_results_df['precision'].head(400000).reset_index(drop=True).plot()\n",
    "plt.title(\"Precision at K\")\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.ylim(top=0.6,bottom=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "estimator = LGBMClassifier()\n",
    "rfc_results_dict, rfc_results_df = run_models(estimator=estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
